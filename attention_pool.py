# -*- coding: utf-8 -*-
"""attention_pool.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CogdUSIYUoA4uHsjMfNH8LNs9-dnNOdJ
"""

import numpy as np

# =========================================================
# Attention Pooling for Protein Embeddings
# =========================================================

class AttentionPoolResult:
    """Store attention-pooled embeddings and assignment labels."""
    def __init__(self, pooled_embeddings, assignment_labels):
        self.pooled_embeddings_ = pooled_embeddings
        self.labels_ = assignment_labels

def apply_attention_pooling(protein_embeddings, n_centers=200, fit_limit=15970):
    """
    Apply attention-based pooling to protein embeddings to reduce dimensionality.
    """
    n_samples = protein_embeddings.shape[0]
    embeddings_to_fit = protein_embeddings[:min(n_samples, fit_limit), :]

    if embeddings_to_fit.size == 0:
        centers = np.zeros((n_centers, protein_embeddings.shape[1]))
        labels = np.zeros((0,), dtype=np.int32)
        return centers, AttentionPoolResult(centers, labels)

    X_mean = embeddings_to_fit.mean(axis=0, keepdims=True)
    try:
        U, S, VT = np.linalg.svd(embeddings_to_fit - X_mean, full_matrices=False)
        pc1 = (embeddings_to_fit - X_mean) @ VT.T[:,0]
    except Exception:
        pc1 = embeddings_to_fit[:,0]

    order = np.argsort(pc1)
    m = order.shape[0]
    idxs = np.linspace(0, m-1, min(n_centers, m)).astype(int)
    anchor_indices = order[idxs] if m >= n_centers else np.tile(order, int(np.ceil(n_centers/m)))[:n_centers]
    anchors = embeddings_to_fit[anchor_indices, :]

    sim = embeddings_to_fit @ anchors.T
    sim_max = np.max(sim, axis=1, keepdims=True)
    exp_sim = np.exp(sim - sim_max)
    weights = exp_sim / (np.sum(exp_sim, axis=1, keepdims=True) + 1e-12)

    numerator = weights.T @ embeddings_to_fit
    denom = np.sum(weights, axis=0)[:, None]
    eps = 1e-12
    zero_mask = (denom.squeeze() < eps)
    centers = numerator / (denom + eps)
    if np.any(zero_mask):
        centers[zero_mask, :] = anchors[zero_mask, :]

    labels = np.argmax(weights, axis=1).astype(np.int32)
    return centers, AttentionPoolResult(centers, labels)

def update_protein_drug_matrix(matrix, pool_result):
    n_centers = pool_result.pooled_embeddings_.shape[0]
    n_drugs = matrix.shape[1]
    updated_matrix = np.zeros((n_centers, n_drugs), dtype=matrix.dtype)
    labels = pool_result.labels_
    for i in range(n_centers):
        mask = (labels == i)
        if np.any(mask):
            updated_matrix[i, :] = np.max(matrix[mask, :], axis=0)
    return updated_matrix

def update_protein_cell_matrix(matrix, pool_result):
    n_centers = pool_result.pooled_embeddings_.shape[0]
    n_cells = matrix.shape[1]
    updated_matrix = np.zeros((n_centers, n_cells), dtype=matrix.dtype)
    labels = pool_result.labels_
    for i in range(n_centers):
        mask = (labels == i)
        if np.any(mask):
            updated_matrix[i, :] = np.max(matrix[mask, :], axis=0)
    return updated_matrix