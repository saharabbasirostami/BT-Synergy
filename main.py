# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qu4DibvYNJ831Lw1763RVhIMj6XUV7mp
"""

# main.py
from data_utils import *
from attention_pool import *
import tensorflow as tf
from tensorflow.keras import layers, Model
# -----------------------------
# Load data
# -----------------------------
path_dataset = '/content/drive/MyDrive/BT-Synergy/dataset/'
dataset = 'DrugCombDB'

list_of_prots = get_list_of_proteins(path_dataset, dataset)
list_of_drugs = get_list_of_drugs(path_dataset, dataset)
list_of_cells = get_list_of_cells(path_dataset, dataset)
protein_drug_matrix = read_protein_drug_matrix(path_dataset, dataset, list_of_prots, list_of_drugs)
protein_cell_matrix = read_protein_cell_matrix(path_dataset, dataset, list_of_prots, list_of_cells)

selfies_unique = np.load(path_dataset + dataset + '/selfies.npy')

drugs_combinations, indx_of_drugs1_combinations, indx_of_drugs2_combinations, indx_of_cells_combinations = read_drug_combinations_data(
    path_dataset, dataset, list_of_drugs, list_of_cells
)

# Load protein embeddings
embeddings_path = '/content/drive/MyDrive/BT-Synergy/dataset/DrugCombDB/protein_embeddings.npy'
protein_embeddings = np.load(embeddings_path)

# Attention Pooling on protein embeddings
protein_embeddings_centers, attention_pool_result = apply_attention_pooling_on_proteins(protein_embeddings)
protein_drug_matrix = update_protein_drug_matrix_by_pooling(protein_drug_matrix, attention_pool_result)
protein_cell_matrix = update_protein_cell_matrix_by_pooling(protein_cell_matrix, attention_pool_result)

# -----------------------------
# Hyperparameters
# -----------------------------
selfies_max_len = 200
patch_size = 20
num_patches = selfies_max_len // patch_size
projection_dim = 50
transformer_layers = 4
num_heads = 1
dropout_attn = 0.1
blstm_units = projection_dim // 2
mlp_head_units = [512, 256, 128]
num_classes = 2

# -----------------------------
# Custom metrics
# -----------------------------
def f1_score_custom(y_true, y_pred):
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(K.round(y_pred), 'float32')
    tp = K.sum(y_true * y_pred, axis=0)
    fp = K.sum((1 - y_true) * y_pred, axis=0)
    fn = K.sum(y_true * (1 - y_pred), axis=0)
    precision_v = tp / (tp + fp + K.epsilon())
    recall_v = tp / (tp + fn + K.epsilon())
    f1 = 2 * (precision_v * recall_v) / (precision_v + recall_v + K.epsilon())
    return K.mean(f1)

def combined_f1_recall(y_true, y_pred):
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(K.round(y_pred), 'float32')
    tp = K.sum(y_true * y_pred, axis=0)
    fp = K.sum((1 - y_true) * y_pred, axis=0)
    fn = K.sum(y_true * (1 - y_pred), axis=0)
    precision = tp / (tp + fp + K.epsilon())
    recall = tp / (tp + fn + K.epsilon())
    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())
    combined = 0.7 * f1 + 0.3 * recall
    return K.mean(combined)

METRICS = [
    tf.keras.metrics.BinaryAccuracy(name='accuracy'),
    tf.keras.metrics.Precision(name='precision'),
    tf.keras.metrics.Recall(name='recall'),
    tf.keras.metrics.AUC(name='auc'),
    tf.keras.metrics.AUC(name='prc', curve='PR'),
    f1_score_custom,
    combined_f1_recall
]

# -----------------------------
# Model building blocks
# -----------------------------
class Patches(layers.Layer):
    def __init__(self, patch_size):
        super().__init__()
        self.patch_size = patch_size

    def call(self, images):
        batch_size = tf.shape(images)[0]
        patches = tf.reshape(images, [batch_size, -1, self.patch_size])
        return patches

class PatchEncoder(layers.Layer):
    def __init__(self, num_patches, projection_dim):
        super().__init__()
        self.num_patches = num_patches
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(
            input_dim=num_patches, output_dim=projection_dim
        )

    def call(self, patch):
        positions = tf.range(start=0, limit=self.num_patches, delta=1)
        encoded = self.projection(patch) + self.position_embedding(positions)
        return encoded

def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = layers.Dense(units, activation=tf.nn.gelu)(x)
        x = layers.Dropout(dropout_rate)(x)
    return x

def transformer_blstm_block(encoded_sequence, projection_dim, num_heads, dropout_attn, blstm_units, transformer_layers):
    x = encoded_sequence
    for _ in range(transformer_layers):
        attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=dropout_attn)(x, x)
        x2 = layers.Add()([attn, x])
        blstm_out = layers.Bidirectional(layers.LSTM(blstm_units, return_sequences=True))(x2)
        ln = layers.LayerNormalization(epsilon=1e-6)(blstm_out)
        x = layers.Add()([x2, ln])
    representation = layers.LayerNormalization(epsilon=1e-6)(x)
    representation = layers.Flatten()(representation)
    representation = layers.Dropout(0.5)(representation)
    return representation

def build_model():
    Drug1_input = Input(shape=(selfies_max_len, 1), name='drug1_input')
    Drug2_input = Input(shape=(selfies_max_len, 1), name='drug2_input')
    Cell_input = Input(shape=(protein_cell_matrix.shape[1],), name='cell_input')

    patches_1 = Patches(patch_size)(Drug1_input)
    encoded_patches_1 = PatchEncoder(num_patches, projection_dim)(patches_1)
    representation_1 = transformer_blstm_block(encoded_patches_1, projection_dim, num_heads, dropout_attn, blstm_units, transformer_layers)

    patches_2 = Patches(patch_size)(Drug2_input)
    encoded_patches_2 = PatchEncoder(num_patches, projection_dim)(patches_2)
    representation_2 = transformer_blstm_block(encoded_patches_2, projection_dim, num_heads, dropout_attn, blstm_units, transformer_layers)

    merged_drugs = layers.Concatenate()([representation_1, representation_2])
    features = mlp(merged_drugs, hidden_units=mlp_head_units, dropout_rate=0.5)
    cell_proj = layers.Dense(features.shape[-1])(Cell_input)

    mult = layers.Multiply()([features, cell_proj])
    add = layers.Add()([features, cell_proj])
    sub = layers.Subtract()([features, cell_proj])
    concat = layers.Concatenate()([features, cell_proj])
    combined = layers.Concatenate()([mult, add, sub, concat])

    combined = layers.LayerNormalization()(combined)
    combined = layers.Dropout(0.3)(combined)
    logits = layers.Dense(1, activation='sigmoid')(combined)

    model = Model(inputs=[Drug1_input, Drug2_input, Cell_input], outputs=logits)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss=tfa.losses.SigmoidFocalCrossEntropy(),
        metrics=METRICS
    )
    return model

# -----------------------------
# Data augmentation
# -----------------------------
def augment_sequences(X1, X2, X_cell, labels):
    augmented_X1, augmented_X2, augmented_Xc, augmented_labels = [], [], [], []
    for i in range(len(X1)):
        augmented_X1.append(X1[i])
        augmented_X2.append(X2[i])
        augmented_Xc.append(X_cell[i])
        augmented_labels.append(labels[i])
        # Swap drugs
        augmented_X1.append(X2[i])
        augmented_X2.append(X1[i])
        augmented_Xc.append(X_cell[i])
        augmented_labels.append(labels[i])
    return np.array(augmented_X1), np.array(augmented_X2), np.array(augmented_Xc), np.array(augmented_labels)

# -----------------------------
# Prepare data
# -----------------------------
indx_d1 = np.array(indx_of_drugs1_combinations)
indx_d2 = np.array(indx_of_drugs2_combinations)
indx_cells = np.array(indx_of_cells_combinations)
labels = np.array(drugs_combinations).reshape(-1, 1)

X1_seq = selfies_unique[indx_d1]
X2_seq = selfies_unique[indx_d2]
X1_seq = np.expand_dims(X1_seq, axis=-1)
X2_seq = np.expand_dims(X2_seq, axis=-1)
X_cell = protein_cell_matrix[indx_cells]

X1_seq, X2_seq, X_cell, labels = augment_sequences(X1_seq, X2_seq, X_cell, labels)

# -----------------------------
# Split 10% for external test
# -----------------------------
X1_trainval, X1_test, X2_trainval, X2_test, Xc_trainval, Xc_test, y_trainval, y_test = train_test_split(
    X1_seq, X2_seq, X_cell, labels, test_size=0.1, random_state=42, stratify=labels
)

# -----------------------------
# K-Fold Cross Validation
# -----------------------------
kf = KFold(n_splits=5, shuffle=True, random_state=42)
best_metrics_all_folds = []

for fold, (train_index, val_index) in enumerate(kf.split(X1_trainval), 1):
    print(f"\nüîÅ Fold {fold} start...")

    X1_train, X1_val = X1_trainval[train_index], X1_trainval[val_index]
    X2_train, X2_val = X2_trainval[train_index], X2_trainval[val_index]
    Xc_train, Xc_val = Xc_trainval[train_index], Xc_trainval[val_index]
    y_train, y_val = y_trainval[train_index], y_trainval[val_index]

    model = build_model()
    log_path = f"training_log_fold{fold}.csv"
    csv_logger = CSVLogger(log_path)

    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train.flatten())
    class_weight_dict = dict(enumerate(class_weights))

    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    model.fit(
        [X1_train, X2_train, Xc_train],
        y_train,
        validation_data=([X1_val, X2_val, Xc_val], y_val),
        epochs=150,
        batch_size=32,
        callbacks=[csv_logger, early_stop],
        class_weight=class_weight_dict,
        verbose=2
    )

    log_data = np.genfromtxt(log_path, delimiter=',', names=True, encoding='utf-8')
    best_metrics = {name: np.max(log_data[name]) for name in log_data.dtype.names if name.startswith("val_")}
    best_metrics_all_folds.append(best_metrics)

    print(f"\nüìä Best metrics Fold {fold}:")
    for k, v in best_metrics.items():
        print(f"{k}: {v:.4f}")

# -----------------------------
# Evaluate on external test set
# -----------------------------
final_metrics = model.evaluate([X1_test, X2_test, Xc_test], y_test, verbose=2)
print("\nüìä Metrics on external test set:", final_metrics)

# -----------------------------
# Save final model
# -----------------------------
model.save('/content/drive/MyDrive/BT-Synergy/final_model.h5')